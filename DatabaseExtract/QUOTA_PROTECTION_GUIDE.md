# YouTube API Quota Protection Guide

## Overview

This notebook has been updated with intelligent quota management to prevent API errors and automatically fall back to cached data when necessary.

## Key Changes

### 1. **Pipeline Cell (Cell ~54)** - PRIMARY DATA SOURCE ‚úÖ

- **Feature**: Tries API first, falls back to cached CSV
- **Error Handling**: Catches `403 quotaExceeded` errors gracefully
- **Status**: Fully implemented with error handling
- **Code**:
  ```python
  try:
      # Try API first
      pipeline = CommunityAnalysisPipeline(API_KEY, ...)
      df_master = pipeline.run(...)
  except HttpError as e:
      if '403' in str(e) and 'quota' in str(e).lower():
          # Load cached CSV
          df_master = pd.read_csv('cluster_results/01_full_comments_with_clusters.csv')
  ```

### 2. **Video ID Setup Cell (Cell ~7)** - DISABLED ‚úÖ

- **Previous**: Made direct YouTube API calls
- **Now**: Only sets VIDEO_ID variable, no API calls
- **Reason**: Prevent quota errors from early cells
- **Impact**: Zero quota consumption

### 3. **Legacy Data Extraction Cell (Cell ~16)** - DISABLED ‚úÖ

- **Previous**: Made direct YouTube API calls with 100+ records
- **Now**: Shows informational message, recommends modern pipeline
- **Reason**: Legacy code was quota-inefficient
- **Impact**: Zero quota consumption

## Workflow

### Running the Notebook

1. ‚úÖ Run cells 1-15 (setup, imports, configuration) - NO quota usage
2. ‚úÖ Skip cells 16-53 (legacy data extraction) - they're disabled
3. ‚úÖ Run cell 54 (pipeline) - SMART quota usage:
   - If API available ‚Üí fetches fresh data
   - If quota exceeded ‚Üí loads cached data automatically
4. ‚úÖ Run remaining visualization cells - work with either API or cached data

### When API Quota is Exceeded

- **You see**: "‚ö† API quota exceeded. Loading from cached CSV instead..."
- **What happens**: Automatically loads from `cluster_results/01_full_comments_with_clusters.csv`
- **No action needed**: Analysis continues seamlessly
- **Next day**: Quota resets, fresh data can be fetched again

## Cached Data Location

```
cluster_results/
‚îú‚îÄ‚îÄ 01_full_comments_with_clusters.csv      ‚Üê Main cache (300 comments, 272 users)
‚îú‚îÄ‚îÄ 02_user_cluster_assignments.csv         ‚Üê User cluster mappings
‚îú‚îÄ‚îÄ 03_behavioral_cluster_profiles.csv      ‚Üê Behavior statistics
‚îî‚îÄ‚îÄ 04_community_statistics.csv             ‚Üê Network community stats
```

## API Quota Reset

- **YouTube API quota**: Resets daily at **midnight UTC**
- **Your quota**: 10,000 units/day per API key
- **Cost per request**: ~1 unit per commentThreads list call
- **Recommendation**: Run pipeline once per day after quota reset

## Error Messages

### Expected Messages

```
üì° Attempting to fetch fresh data from YouTube API...
‚úì Successfully fetched 300 comments...
```

### Fallback Messages

```
‚ö† API quota exceeded. Loading from cached CSV instead...
‚úì Loaded 300 cached records from previous execution
```

## Troubleshooting

| Problem               | Solution                                                    |
| --------------------- | ----------------------------------------------------------- |
| "quotaExceeded" error | Normal - pipeline automatically uses cache                  |
| Cache file not found  | Run pipeline once with fresh API data to create it          |
| Want fresh data today | Wait until next day for quota reset                         |
| Cache is outdated     | Delete `cluster_results/` and run pipeline with fresh quota |

## Technical Details

### Pipeline Error Handling

- Catches specific `HttpError` 403 quota exceeded
- Re-raises other HTTP errors for visibility
- Catches generic exceptions with graceful fallback
- Provides clear feedback on which source (API vs cache) is being used

### CSV Cache Strategy

- Created during first successful pipeline run
- Automatically used as fallback
- Can be manually regenerated by deleting and re-running
- Contains full clustering and sentiment analysis results

## Summary

‚úÖ **The notebook is now quota-resilient** - it will work reliably even when the YouTube API quota is exhausted, automatically falling back to cached results.
